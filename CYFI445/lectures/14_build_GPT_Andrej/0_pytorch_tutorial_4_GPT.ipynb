{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5e29d1",
   "metadata": {},
   "source": [
    "### Review Shape\n",
    "\n",
    "![shape](https://cdn-images-1.medium.com/max/2000/1*_D5ZvufDS38WkhK9rK32hQ.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a65750",
   "metadata": {},
   "source": [
    "###  A 3D tensor is common in many machine learning (ML) applications, especially when dealing with sequences, batches, or multi-channel data.\n",
    "- General Shape: [batch_size, seq_len, feature_dim]\n",
    "- This is the most common 3D tensor format.\n",
    "\n",
    "### Common Scenarios\n",
    "- NLP (Natural Language Processing)\n",
    "    - Shape: [batch_size, seq_len, embedding_dim]\n",
    "    - Example: Word embeddings for a batch of sentences.\n",
    "        - batch_size: number of sentences\n",
    "        - seq_len: number of words per sentence\n",
    "        - embedding_dim: size of word embeddings (e.g., 300 or 768)\n",
    "\n",
    "- Time Series / Sequence Models\n",
    "    - Shape: [batch_size, time_steps, features]\n",
    "    - Example: Predicting stock prices from multivariate time series.\n",
    "        - Each sample has time steps (e.g., 30 days)\n",
    "        - Each time step has features (e.g., open, high, low, volume)\n",
    "\n",
    "- Audio Processing\n",
    "    - Shape: [batch_size, num_frames, feature_dim]\n",
    "    - Example: Spectrograms or MFCC features.\n",
    "        - Each audio clip is broken into frames (e.g., 100 ms)\n",
    "        - Each frame has a feature vector\n",
    "\n",
    "- Video Data\n",
    "    - Shape: [batch_size, num_frames, flattened_image_features]\n",
    "    - Example: Extracting features per frame using CNN, then feeding to RNN for action recognition.\n",
    "\n",
    "- Transformer Models (Self-Attention)\n",
    "    - Shape: [batch_size, seq_len, model_dim]\n",
    "    - Used throughout in attention mechanisms to compute queries, keys, and values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea65a9",
   "metadata": {},
   "source": [
    "### Python list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "292304d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = [1, 2, 3, 4, 5]\n",
    "[ i**2 for i in list ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efceddf4",
   "metadata": {},
   "source": [
    "### anonymous function \n",
    "- A lambda is a short way to write a function \n",
    "- a function without a name.\n",
    "\n",
    "`def square(x):`\n",
    "    `return x ** 2 `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "396244a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "square = lambda x: x ** 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f6c1a",
   "metadata": {},
   "source": [
    "### generate random integers drawn from a specified range.\n",
    "`torch.randint(low, high, size, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d144e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 0, 7],\n",
       "        [0, 8, 8]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2x3 tensor of random integers from 0 to 10 (excluding 10)\n",
    "import torch\n",
    "x = torch.randint(0, 10, (2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "309281c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(10, (2,))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876079c8",
   "metadata": {},
   "source": [
    "### swap two dimensions of a tensor\n",
    "\n",
    "`torch.transpose(input, dim0, dim1)`\n",
    "- `input`: The input tensor.\n",
    "- `dim0, dim1`: The two dimensions to swap.\n",
    "- dim0 = 0 (rows), dim1 = 1 (columns) — so rows become columns and vice versa.\n",
    "- Effectively: it transposes the matrix like in linear algebra.\n",
    "\n",
    "![transpose](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*HRWWBxD3H0rkO4r5J64dVg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "489c9230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 5],\n",
      "        [2, 4, 6]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])  # Shape: (3, 2)\n",
    "\n",
    "b = torch.transpose(a, 0, 1)\n",
    "print(b)\n",
    "# Output:\n",
    "# tensor([[1, 3, 5],\n",
    "#         [2, 4, 6]])\n",
    "print(b.shape)  # torch.Size([2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b1fe2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 24).reshape(2, 3, 4)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cd3acf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  4,  8],\n",
       "         [ 1,  5,  9],\n",
       "         [ 2,  6, 10],\n",
       "         [ 3,  7, 11]],\n",
       "\n",
       "        [[12, 16, 20],\n",
       "         [13, 17, 21],\n",
       "         [14, 18, 22],\n",
       "         [15, 19, 23]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(a, 1,2) # shape (2, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "598c85b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  4,  8],\n",
       "         [ 1,  5,  9],\n",
       "         [ 2,  6, 10],\n",
       "         [ 3,  7, 11]],\n",
       "\n",
       "        [[12, 16, 20],\n",
       "         [13, 17, 21],\n",
       "         [14, 18, 22],\n",
       "         [15, 19, 23]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent to  torch.transpose(a, 1, 2)\n",
    "torch.transpose(a, -1,-2) # shape (2, 4, 3) \n",
    "# -1 refers to the last dimension (dim 2, which is 4),\n",
    "# -2 refers to second-last (dim 1, which is 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a0449",
   "metadata": {},
   "source": [
    "### shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bcf9f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 24).reshape(2, 3, 4)\n",
    "a.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7d11cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 4\n"
     ]
    }
   ],
   "source": [
    "B, T, C = a.shape # unpack\n",
    "print(B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a54e3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(-1, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41704236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(-1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd75e9a",
   "metadata": {},
   "source": [
    "### torch Stack (add a new dimension)\n",
    "Often add traning data as batch\n",
    "\n",
    "- torch.stack — Stack along a new dimension\n",
    "- Think: Create a new axis (like stacking flat sheets into a pile).\n",
    "- Requirement: Tensors must have exactly the same shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef38dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3],\n",
    "                 [4, 5, 6]]) # shape (2,3)\n",
    "b = torch.tensor([[7, 8, 9],\n",
    "                 [10, 11, 12]])\n",
    "\n",
    "batch=torch.stack([a, b], dim = 0) # dim=0 is default. shape (2,2,3)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3038ae",
   "metadata": {},
   "source": [
    "### cat and stack\n",
    "- torch.cat — Concatenate along an existing dimension\n",
    "- Think: Extend an axis (like adding more rows to a table).\n",
    "- Requirement: Tensors must have the same shape in all dimensions except the one you're concatenating along.\n",
    "\n",
    "![Cat](https://user-images.githubusercontent.com/111734605/235976058-d23f9b75-401c-4547-9e17-6655f3baf957.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b40936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3],\n",
    "                 [4, 5, 6]])\n",
    "b = torch.tensor([[7, 8, 9],\n",
    "                 [10, 11, 12]])\n",
    "\n",
    "torch.cat([a, b], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a3becff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  7,  8,  9],\n",
       "        [ 4,  5,  6, 10, 11, 12]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b], dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee89070",
   "metadata": {},
   "source": [
    "### torch zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93957703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c36a8481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe1bb17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55c949",
   "metadata": {},
   "source": [
    "### F.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe6b1846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "# A list\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logits = torch.tensor([2.0, 1.0, 0.1])\n",
    "probs = F.softmax(logits, dim=0)\n",
    "print(probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745e09f",
   "metadata": {},
   "source": [
    "In PyTorch, softmax requires a dim to tell it which axis to normalize over. Since there's only one axis here (axis 0), you must use dim=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70739a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6590, 0.2424, 0.0986],\n",
      "        [0.1131, 0.8360, 0.0508]])\n"
     ]
    }
   ],
   "source": [
    "# A batch of 2 samples, each with 3 class scores (logits)\n",
    "logits = torch.tensor([[2.0, 1.0, 0.1],\n",
    "                       [1.0, 3.0, 0.2]])\n",
    "\n",
    "# Apply softmax along dim=1 (columns — the class dimension)\n",
    "probs = F.softmax(logits, dim=1)\n",
    "\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b02c8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6590, 0.2424, 0.0986],\n",
       "        [0.1131, 0.8360, 0.0508]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, dim=-1) # same as probs = F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72741021",
   "metadata": {},
   "source": [
    "- Apply softmax over the last dimension of the tensor, no matter how many dimensions it has.\n",
    "- dim=-1 is a convenient and general way to apply softmax across the correct axis — especially in batch scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a4de9a",
   "metadata": {},
   "source": [
    "### Masks\n",
    "- `torch.tril(input, diagonal=0)`\n",
    "- It returns the lower triangular part of a matrix (or batch of matrices), setting elements above the specified diagonal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e5d2bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0],\n",
      "        [4, 5, 0],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "lower = torch.tril(a)\n",
    "print(lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cebf6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7eea60",
   "metadata": {},
   "source": [
    "###  A variable that is part of the model, used for computation, but not learned: `register_buffer('tril', tensor)`\n",
    "-  is a PyTorch method used inside a nn.Module subclass to store a tensor as part of the model, without treating it as a learnable parameter (i.e., it's not updated during training by optimizer.step()).\n",
    "- variable\n",
    "    - It is not a parameter (won’t be updated during training)\n",
    "    - It is essential for forward pass or internal logic\n",
    "    - It stays with the model — moves to GPU, saved/loaded with weights\n",
    "- Why need it?\n",
    "    - Constant tensors needed during forward pass but should not be updated during training (e.g., masks, position encodings, identity matrices, etc.) → You still want them to:\n",
    "        - Move with the model (`.cuda()` or `.to(device)`)\n",
    "        - Save/load with the model (`.state_dict()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a24ff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        tril = torch.tril(torch.ones(n, n))\n",
    "        self.register_buffer('tril', tril)  # Register buffer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the registered lower-triangular mask\n",
    "        return x * self.tril\n",
    "\n",
    "model = MyModel(4)\n",
    "print(model.tril)  # Access the registered buffer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2cb8f8",
   "metadata": {},
   "source": [
    "### nn.Embedding: a lookup table that maps integer indices to dense vectors \n",
    "- it's commonly used to convert tokens (like words or characters) into embeddings for use in neural networks.\n",
    "- `nn.Embedding(num_embeddings, embedding_dim)`\n",
    "    - num_embeddings: total number of unique tokens (e.g., vocabulary size)\n",
    "    - embedding_dim: size of each embedding vector (e.g., 100-dimensional vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6447f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0356, -0.4012,  0.2564,  1.4654],\n",
      "         [-0.3390, -0.5554,  1.3577,  0.2175],\n",
      "         [-0.9895, -0.1303, -0.0827, -0.8324]],\n",
      "\n",
      "        [[-0.9895, -0.1303, -0.0827, -0.8324],\n",
      "         [-0.6834,  0.9849,  0.7157,  1.7701],\n",
      "         [-0.3390, -0.5554,  1.3577,  0.2175]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define embedding: vocab size = 10, embedding size = 4\n",
    "embedding = nn.Embedding(10, 4)\n",
    "\n",
    "# Input: token indices (batch of 2 sequences with 3 tokens each)\n",
    "input = torch.tensor([[1, 2, 4], [4, 3, 2]]) # shape (2, 3)\n",
    "\n",
    "# Output: shape (2, 3, 4) → each token index becomes a vector with 4 features\n",
    "output = embedding(input) # shape (2, 3, 4)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a725f4",
   "metadata": {},
   "source": [
    "###  samples indices based on probabilities.\n",
    "\n",
    "- `torch.multinomial(input, num_samples, replacement=False)`\n",
    "- input: A 1D or 2D tensor of non-negative values (like probabilities or weights)\n",
    "- num_samples: How many samples to draw\n",
    "- replacement: Whether to sample with or without replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32d1140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.tensor([0.1, 0.3, 0.6])\n",
    "sample = torch.multinomial(weights, num_samples=1)\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b8ea05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.tensor([\n",
    "    [0.1, 0.9],\n",
    "    [0.8, 0.2]\n",
    "])\n",
    "samples = torch.multinomial(weights, 1)\n",
    "print(samples) # shape (2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed2a664",
   "metadata": {},
   "source": [
    "### computing average cross rows (implmentation 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "19244d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=3\n",
    "tril=torch.tril(torch.ones(T,T))\n",
    "tril= tril/torch.sum(tril, 1, keepdim=True)\n",
    "a= torch.randint(0, 10, (T,T)).float()\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f01d0ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 5., 2.],\n",
       "        [4., 3., 8.],\n",
       "        [8., 9., 8.]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "16d32e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0000, 5.0000, 2.0000],\n",
       "        [6.5000, 4.0000, 5.0000],\n",
       "        [7.0000, 5.6667, 6.0000]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril@a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765966e2",
   "metadata": {},
   "source": [
    "### computing average attention cross rows (implmentation 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e7d1dcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention in logits\n",
      " tensor([[5., 0., 9.],\n",
      "        [4., 1., 7.],\n",
      "        [4., 3., 6.]])\n",
      "masked attentioin\n",
      " tensor([[5., -inf, -inf],\n",
      "        [4., 1., -inf],\n",
      "        [4., 3., 6.]])\n",
      "masked attentioin with averageed softmax\n",
      " tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.9526, 0.0474, 0.0000],\n",
      "        [0.1142, 0.0420, 0.8438]])\n"
     ]
    }
   ],
   "source": [
    "# tensor.masked_fill(mask, value) \n",
    "# sets elements of a tensor to a given value where the mask is True.\n",
    "\n",
    "import torch\n",
    "\n",
    "T=3\n",
    "# self-attention weight\n",
    "w= torch.randint(0, 10, (T,T)).float() # (T,T)\n",
    "print(\"attention in logits\\n\", w) \n",
    "\n",
    "# mask so that self-attention won't learn from later characters\n",
    "tril=torch.tril(torch.ones(T,T))\n",
    "# print(tril==0)  # tril[:T, :T] ==0 equivlent  (T,T)\n",
    "\n",
    "# Set elements where tril==0 (only attend to current characters, not future generated characters) to -inf\n",
    "w = w.masked_fill(tril==0, float('-inf'))\n",
    "print(\"masked attentioin\\n\", w)\n",
    "print(\"masked attentioin with averageed softmax\\n\", F.softmax(w, dim=-1)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0502f238",
   "metadata": {},
   "source": [
    "### layerNorm: normlize all features of each input (e.g., token)\n",
    "- \"Re-centering and resizing\" each token's representation so that it’s easier for the next layer to work with — regardless of what happened in earlier layers.\n",
    "- LayerNorm centers (zero mean) and scales (unit variance) each token's features, ensuring the activations passed to the next layer stay in a stable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f83fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2247,  0.0000,  1.2247],\n",
      "        [-1.2247,  0.0000,  1.2247]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0], [2.0, 4.0, 6.0]])\n",
    "layer_norm = nn.LayerNorm(x.shape[1])  # Normalize across last dimension\n",
    "output = layer_norm(x)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f1e976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e6b9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2247, 1.2247], grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353147ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2247, grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0,:].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feeabaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
