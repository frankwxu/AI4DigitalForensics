{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ca8277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:07<00:00, 24.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.535, Accuracy: 44.58%\n",
      "Epoch 2, Loss: 1.254, Accuracy: 54.91%\n",
      "Epoch 3, Loss: 1.144, Accuracy: 59.47%\n",
      "Epoch 4, Loss: 1.071, Accuracy: 62.25%\n",
      "Epoch 5, Loss: 1.017, Accuracy: 64.26%\n",
      "Epoch 6, Loss: 0.975, Accuracy: 65.75%\n",
      "Epoch 7, Loss: 0.945, Accuracy: 67.02%\n",
      "Epoch 8, Loss: 0.916, Accuracy: 68.16%\n",
      "Epoch 9, Loss: 0.892, Accuracy: 68.86%\n",
      "Epoch 10, Loss: 0.865, Accuracy: 70.02%\n",
      "\n",
      "Test Accuracy: 73.62%\n",
      "Training complete. Plots saved as 'training_metrics.png', 'confusion_matrix.png', and 'sample_predictions.png'\n"
     ]
    }
   ],
   "source": [
    "import torch  # PyTorch library for tensor computations and deep learning\n",
    "import torch.nn as nn  # Neural network modules\n",
    "import torch.nn.functional as F  # Functional interface for neural network operations\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import torchvision  # Computer vision datasets and models\n",
    "import torchvision.transforms as transforms  # Image transformations\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import numpy as np  # Numerical computations\n",
    "from sklearn.metrics import confusion_matrix  # For confusion matrix\n",
    "import seaborn as sns  # Visualization library for confusion matrix\n",
    "\n",
    "# Set random seed for reproducibility across runs\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define data transformations for preprocessing\n",
    "# - RandomHorizontalFlip: Randomly flip images horizontally for data augmentation\n",
    "# - RandomRotation: Randomly rotate images by up to 10 degrees for augmentation\n",
    "# - ToTensor: Convert images to PyTorch tensors (HWC to CHW format)\n",
    "# - Normalize: Normalize RGB channels with mean=0.5 and std=0.5\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 training dataset\n",
    "# - root: Directory to store dataset\n",
    "# - train: True for training set\n",
    "# - download: Download dataset if not present\n",
    "# - transform: Apply defined transformations\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "# Create DataLoader for training set\n",
    "# - batch_size: Number of images per batch (64)\n",
    "# - shuffle: Randomly shuffle data for better training\n",
    "# - num_workers: Number of subprocesses for data loading\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Load CIFAR-10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "# Create DataLoader for test set\n",
    "# - shuffle: False to maintain order for evaluation\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Define class labels for CIFAR-10\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Define CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # First convolutional layer: 3 input channels (RGB), 32 output channels, 3x3 kernel\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        # Second convolutional layer: 32 input channels, 64 output channels, 3x3 kernel\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # Max pooling layer: 2x2 kernel, stride 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Batch normalization for first conv layer\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        # Batch normalization for second conv layer\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # First fully connected layer: Input size calculated from conv output (64*8*8), 512 units\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        # Second fully connected layer: 512 units to 10 output classes\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        # Dropout layer with 50% probability to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        # Conv1 -> BatchNorm -> ReLU -> MaxPool\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # Conv2 -> BatchNorm -> ReLU -> MaxPool\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        # Flatten the output for fully connected layers\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        # Fully connected layer 1 -> ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        # Final fully connected layer for classification\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model and move to appropriate device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "\n",
    "# Define loss function (CrossEntropyLoss for multi-class classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define optimizer (Adam with learning rate 0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Number of training epochs\n",
    "train_losses = []  # Store loss per epoch\n",
    "train_accuracies = []  # Store accuracy per epoch\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0  # Track total loss for epoch\n",
    "    correct = 0  # Track correct predictions\n",
    "    total = 0  # Track total samples\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels, move to device\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate and store epoch metrics\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.3f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "# Evaluate model on test set\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []  # Store predictions for confusion matrix\n",
    "all_labels = []  # Store true labels\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and print test accuracy\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Plot training metrics (loss and accuracy)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_metrics.png')  # Save plot\n",
    "plt.close()\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('confusion_matrix.png')  # Save plot\n",
    "plt.close()\n",
    "\n",
    "# Function to unnormalize and display images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))  # Convert from CHW to HWC\n",
    "\n",
    "# Show sample test images with predictions\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images[:8].to(device), labels[:8]\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(imshow(images[i].cpu()))\n",
    "    plt.title(f'Pred: {classes[predicted[i]]}\\nTrue: {classes[labels[i]]}')\n",
    "    plt.axis('off')\n",
    "plt.savefig('sample_predictions.png')  # Save plot\n",
    "plt.close()\n",
    "\n",
    "print(\"Training complete. Plots saved as 'training_metrics.png', 'confusion_matrix.png', and 'sample_predictions.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
