{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13e10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98233002",
   "metadata": {},
   "source": [
    "### Batch inputs (two sentences) have different number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d577d7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Matrix is great', 'A terrible movie']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review1=\"The Matrix is great\" # 5 tokens\n",
    "review2=\"A terrible movie\" # 4 tokens\n",
    "\n",
    "reviews = [review1, review2]\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c81860",
   "metadata": {},
   "source": [
    "### BERT processes Batch inputs to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c86600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer and model (frozen)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  # Load tokenizer\n",
    "\n",
    "# Batch all phrases together\n",
    "inputs = tokenizer(\n",
    "    reviews,  # all texts at once\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6749e737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c53ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "print(inputs['input_ids'].shape)         # torch.Size([batch_size, seq_len])\n",
    "print(inputs['attention_mask'].shape)    # torch.Size([batch_size, seq_len])\n",
    "print(inputs['token_type_ids'].shape)    # torch.Size([batch_size, seq_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132bb7a",
   "metadata": {},
   "source": [
    "### padding when two sentences have different len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939aee8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101, 1037, 6659, 3185,  102,    0])\n",
      "['[CLS]', 'a', 'terrible', 'movie', '[SEP]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(inputs['input_ids'][1]) # Token IDs\n",
    "print(tokenizer.convert_ids_to_tokens(inputs['input_ids'][1])) # Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e54773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('bert-base-uncased')          # Load model for embeddings\n",
    "model.eval()  # Set to evaluation mode (no training)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceda8fe",
   "metadata": {},
   "source": [
    "### Sentences and 3D dimension. Assume\n",
    "- 3 sentences, \n",
    "- each sentence has 2 words, \n",
    "- each word has 5 features, \n",
    "\n",
    "![shapes](https://www.tensorflow.org/static/guide/images/tensor/3-axis_front.png)\n",
    "\n",
    "#### What is dimension of sentence embeddings?\n",
    "- (3,5)\n",
    "\n",
    "`nn.mean(data, dim=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1cf20",
   "metadata": {},
   "source": [
    "### Sentence embeddings is the average of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6eac3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1656, -0.2764, -0.0298,  ...,  0.0087, -0.0636,  0.2763],\n",
       "        [ 0.1329,  0.0747, -0.2481,  ..., -0.2341,  0.2315, -0.1357]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(outputs.last_hidden_state, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e57b5",
   "metadata": {},
   "source": [
    "### (Optional) What is the potential issue of use the average of word embeddings for sentence embeddings\n",
    "\n",
    "The mean includes padding tokens (where attention_mask=0), which can dilute the embedding quality. BERTâ€™s padding tokens produce non-informative embeddings, and averaging them may introduce noise, especially for short reviews with many padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae40e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masked mean-pooling\n",
    "attention_mask = inputs['attention_mask']  # (batch_size, seq_len)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24ac0d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand_as(outputs.last_hidden_state)  # (batch_size, seq_len, hidden_dim)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97e4b4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.8348e-02,  9.5097e-02,  1.4332e-02,  ..., -1.7143e-01,\n",
       "           1.2736e-01,  3.7117e-01],\n",
       "         [-3.7472e-01, -6.2022e-01,  1.2133e-01,  ..., -2.7666e-02,\n",
       "           1.5813e-01,  1.7997e-01],\n",
       "         [ 7.1591e-01, -1.9231e-01,  1.5049e-01,  ..., -4.0711e-01,\n",
       "           1.9909e-01,  2.7043e-01],\n",
       "         [-3.6584e-01, -3.0518e-01,  5.0851e-04,  ...,  1.1478e-01,\n",
       "          -2.0296e-01,  9.8816e-01],\n",
       "         [ 4.8723e-02, -7.2430e-01, -1.8481e-01,  ...,  3.9914e-01,\n",
       "           9.7036e-02,  4.0537e-02],\n",
       "         [ 1.0081e+00,  8.8626e-02, -2.8047e-01,  ...,  1.4469e-01,\n",
       "          -7.6039e-01, -1.9232e-01]],\n",
       "\n",
       "        [[-1.0380e-01,  4.6764e-03, -1.2088e-01,  ..., -2.1156e-01,\n",
       "           2.9962e-01, -1.0300e-02],\n",
       "         [-1.1521e-01,  2.1597e-01, -4.0657e-01,  ..., -5.8376e-01,\n",
       "           8.9380e-01,  4.3011e-01],\n",
       "         [ 4.4965e-01,  2.5421e-01,  2.4422e-02,  ..., -3.6552e-01,\n",
       "           2.4427e-01, -6.5578e-01],\n",
       "         [ 6.2745e-02,  6.8042e-02, -9.1592e-01,  ..., -2.1580e-01,\n",
       "          -1.1718e-02, -6.0144e-01],\n",
       "         [ 6.7927e-01,  2.1335e-01, -3.9926e-01,  ...,  8.9958e-03,\n",
       "          -5.5664e-01, -1.6044e-01],\n",
       "         [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = outputs.last_hidden_state * mask\n",
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699205c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
