{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18cc9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program for sentiment analysis of synthetic Rotten Tomatoes reviews for The Matrix\n",
    "# Uses generated dataset of 50 reviews (48 movie reviews + 2 reference texts)\n",
    "# Implements: tokenization, token embeddings, sentiment prediction with frozen BERT and custom layer\n",
    "# Requirements: pip install transformers torch pandas\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0b0e4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Matrix is great, revolutionary sci-fi that...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Terrible movie, The Matrix’s plot is so confus...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Matrix was okay, entertaining but not life...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Great visuals and action in The Matrix make it...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hated The Matrix; terrible pacing and a story ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             phrase sentiment\n",
       "0   1  The Matrix is great, revolutionary sci-fi that...  positive\n",
       "1   2  Terrible movie, The Matrix’s plot is so confus...  negative\n",
       "2   3  The Matrix was okay, entertaining but not life...   neutral\n",
       "3   4  Great visuals and action in The Matrix make it...  positive\n",
       "4   5  Hated The Matrix; terrible pacing and a story ...  negative"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('matrix_reviews.csv', encoding='utf-8')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9c58e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out reference texts (id 49, 50) for sentiment prediction\n",
    "df_reviews = df[df['id'] <= 48].copy()\n",
    "texts = df['phrase'].tolist()  # All texts for tokenization/embeddings\n",
    "labels = df_reviews['sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2}).values  # Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36733cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokens for 'The Matrix is great, revolutionary sci-fi that redefined action films! #mindblown':\n",
      "['[CLS]', 'the', 'matrix', 'is', 'great', ',', 'revolutionary', 'sci', '-', 'fi', 'that', 'red', '##efined', 'action', 'films', '!', '#', 'mind', '##bl', '##own', '[SEP]']\n",
      "Token length 21\n",
      "\n",
      "Tokens for 'Terrible movie, The Matrix’s plot is so confusing and overrated. #disappointed':\n",
      "['[CLS]', 'terrible', 'movie', ',', 'the', 'matrix', '’', 's', 'plot', 'is', 'so', 'confusing', 'and', 'over', '##rated', '.', '#', 'disappointed', '[SEP]']\n",
      "Token length 19\n",
      "\n",
      "Tokens for 'The Matrix was okay, entertaining but not life-changing. #movies':\n",
      "['[CLS]', 'the', 'matrix', 'was', 'okay', ',', 'entertaining', 'but', 'not', 'life', '-', 'changing', '.', '#', 'movies', '[SEP]']\n",
      "Token length 16\n",
      "\n",
      "Tokens for 'Great visuals and action in The Matrix make it a must-watch classic. #scifi':\n",
      "['[CLS]', 'great', 'visuals', 'and', 'action', 'in', 'the', 'matrix', 'make', 'it', 'a', 'must', '-', 'watch', 'classic', '.', '#', 'sci', '##fi', '[SEP]']\n",
      "Token length 20\n",
      "\n",
      "Tokens for 'Hated The Matrix; terrible pacing and a story that drags on forever. #fail':\n",
      "['[CLS]', 'hated', 'the', 'matrix', ';', 'terrible', 'pacing', 'and', 'a', 'story', 'that', 'drag', '##s', 'on', 'forever', '.', '#', 'fail', '[SEP]']\n",
      "Token length 19\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT tokenizer and model (frozen)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  # Load tokenizer\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')          # Load model for embeddings\n",
    "model.eval()  # Set to evaluation mode (no training)\n",
    "\n",
    "# Step 1: Tokenization - Process all texts and store tokens\n",
    "all_tokens = []\n",
    "for text in texts[:5]:  # Show first 5 for brevity\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)  # Tokenize\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])              # Get tokens\n",
    "    all_tokens.append(tokens)\n",
    "    print(f\"\\nTokens for '{text}':\")\n",
    "    print(tokens)\n",
    "    print(f\"Token length {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "068f7cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embeddings for 'The Matrix is great, revolutionary sci-fi that redefined action films! #mindblown' (first token, 5 numbers):\n",
      "[ 0.2202626  -0.18178469 -0.46809724  0.1393926   0.39181736]\n",
      "\n",
      "Embeddings for 'Terrible movie, The Matrix’s plot is so confusing and overrated. #disappointed' (first token, 5 numbers):\n",
      "[0.7884245  0.652363   0.05890564 0.18900512 0.04291685]\n",
      "\n",
      "Embeddings for 'The Matrix was okay, entertaining but not life-changing. #movies' (first token, 5 numbers):\n",
      "[ 0.16382633 -0.20111704 -0.42153656  0.16307226 -0.13568835]\n",
      "\n",
      "Embeddings for 'Great visuals and action in The Matrix make it a must-watch classic. #scifi' (first token, 5 numbers):\n",
      "[ 0.5706272   0.07817388 -0.06764057  0.08270969  0.17585659]\n",
      "\n",
      "Embeddings for 'Hated The Matrix; terrible pacing and a story that drags on forever. #fail' (first token, 5 numbers):\n",
      "[ 0.57143813  0.5018263   0.7289898  -0.03643154 -0.18432716]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Token Embeddings - Generate embeddings for all texts\n",
    "all_embeddings = []\n",
    "for text in texts[:5]:  # Show first 5 for brevity\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)  # Tokenize\n",
    "    with torch.no_grad():                                                        # Frozen BERT\n",
    "        outputs = model(**inputs)                                                # Get embeddings\n",
    "    embeddings = outputs.last_hidden_state[0]                                     # Extract vectors\n",
    "    all_embeddings.append(embeddings)\n",
    "    print(f\"\\nEmbeddings for '{text}' (first token, 5 numbers):\")\n",
    "    print(embeddings[1][:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33f8d62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a5d1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Sentiment Prediction - Train custom layer on frozen BERT embeddings\n",
    "# Custom classifier model\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, num_classes=3):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)  # Single dense layer\n",
    "        self.softmax = nn.Softmax(dim=1) # each column adds to 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e78ee0f",
   "metadata": {},
   "source": [
    "### Sentences and 3D dimension. Assume\n",
    "- 3 sentences, \n",
    "- 2 words, \n",
    "- each word has 5 features, \n",
    "\n",
    "![shapes](https://www.tensorflow.org/static/guide/images/tensor/3-axis_front.png)\n",
    "\n",
    "#### What is dimension of sentence embeddings?\n",
    "- (3,5)\n",
    "\n",
    "`nn.mean(data, dim=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad411bb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Batch all phrases together\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m inputs = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_reviews\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mphrase\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# all texts at once\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     11\u001b[39m     outputs = model(**inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mi:\\conda_envs\\reinforcement\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2887\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2885\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2886\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2887\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2888\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2889\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mi:\\conda_envs\\reinforcement\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2947\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2944\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2946\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[32m-> \u001b[39m\u001b[32m2947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2948\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2949\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2950\u001b[39m     )\n\u001b[32m   2952\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2954\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2955\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2956\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "# Batch all phrases together\n",
    "inputs = tokenizer(\n",
    "    list(df_reviews['phrase']),  # all texts at once\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# outputs.last_hidden_state: (batch_size, seq_len, hidden_dim)\n",
    "# Mean-pool over tokens (dim=1)\n",
    "review_embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # (batch_size, 768)\n",
    "\n",
    "# Convert labels to tensor\n",
    "review_labels = torch.tensor(labels, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa993e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1128\n",
      "Epoch 2, Loss: 1.0926\n",
      "Epoch 3, Loss: 1.0726\n",
      "Epoch 4, Loss: 1.0530\n",
      "Epoch 5, Loss: 1.0337\n",
      "Epoch 6, Loss: 1.0149\n",
      "Epoch 7, Loss: 0.9966\n",
      "Epoch 8, Loss: 0.9793\n",
      "Epoch 9, Loss: 0.9629\n",
      "Epoch 10, Loss: 0.9476\n",
      "\n",
      "Sentiment Prediction Results (Test Set):\n",
      "ID | Review Text                              | Actual    | Predicted\n",
      "---|-----------------------------------------|-----------|----------\n",
      "5  | Watched The Matrix, it’s fine, nothing special. #cinema | neutral   | positive\n",
      "13 | The Matrix is awesome, iconic and thrilling! #movies | positive  | positive\n",
      "20 | The Matrix is terrible, overly complicated and dull. #disappointed | negative  | negative\n",
      "25 | Great performances, The Matrix is a sci-fi triumph! #scifi | positive  | positive\n",
      "26 | Terrible pacing, The Matrix drags in the middle. #boring | negative  | negative\n",
      "27 | Saw The Matrix, neutral, it’s alright. #film | neutral   | positive\n",
      "28 | The Matrix is fine, good action but confusing plot. #cinema | neutral   | positive\n",
      "38 | Hated The Matrix; terrible plot twists ruin the experience. #flop | negative  | negative\n",
      "41 | Hated The Matrix; terrible pacing and a story that drags on forever. #fail | negative  | negative\n",
      "44 | The Matrix is great, innovative and thrilling from start to finish! #movies | positive  | positive\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "train_emb, test_emb, train_labels, test_labels, train_texts, test_texts = train_test_split(\n",
    "    review_embeddings, review_labels, df_reviews['phrase'].tolist(),\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize custom classifier\n",
    "classifier = SentimentClassifier()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "classifier.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = classifier(train_emb)  # Forward pass\n",
    "    loss = criterion(outputs, train_labels)  # Compute loss\n",
    "    loss.backward()  # Backpropagate\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Predict sentiments for test set\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = classifier(test_emb)\n",
    "    y_pred = torch.argmax(test_outputs, dim=1).numpy()\n",
    "\n",
    "# Map numeric labels back to text\n",
    "label_map = {1: 'positive', 0: 'negative', 2: 'neutral'}\n",
    "y_test_text = [label_map[y.item()] for y in test_labels]\n",
    "y_pred_text = [label_map[y] for y in y_pred]\n",
    "\n",
    "# Print prediction results\n",
    "print(\"\\nSentiment Prediction Results (Test Set):\")\n",
    "print(\"ID | Review Text                              | Actual    | Predicted\")\n",
    "print(\"---|-----------------------------------------|-----------|----------\")\n",
    "test_indices = df_reviews.index[df_reviews['phrase'].isin(test_texts)].tolist()\n",
    "for idx, actual, pred, text in zip(test_indices, y_test_text, y_pred_text, test_texts):\n",
    "    print(f\"{idx+1:<2} | {text:<40} | {actual:<9} | {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d50bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
