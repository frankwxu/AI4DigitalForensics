{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translating from English to Chinese (Version1 : using AutoTokenizer, AutoModelForSeq2SeqLM)\n",
        "- not work: pip install sentencepiece \n",
        "- use: conda install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: The cat is sleeping on the mat.\n",
            "Chinese: 猫睡在垫子上\n",
            "\n",
            "English: I love exploring new places.\n",
            "Chinese: 我喜欢探索新的地方\n",
            "\n",
            "English: This is a beautiful sunny day.\n",
            "Chinese: 这是一个美丽的阳光明媚的日子。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-zh\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Function to translate text\n",
        "def translate_text(text):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    \n",
        "    # Generate translation\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=512,\n",
        "            num_beams=4,  # Beam search for better quality\n",
        "            early_stopping=True\n",
        "        )\n",
        "    \n",
        "    # Decode the generated tokens to text\n",
        "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    return translated_text\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample English texts\n",
        "    texts = [\n",
        "        \"The cat is sleeping on the mat.\",\n",
        "        \"I love exploring new places.\",\n",
        "        \"This is a beautiful sunny day.\"\n",
        "    ]\n",
        "    \n",
        "    # Translate each text\n",
        "    for text in texts:\n",
        "        translation = translate_text(text)\n",
        "        print(f\"English: {text}\")\n",
        "        print(f\"Chinese: {translation}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translating from English to Chinese (Version 2 : using pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: The cat is sleeping on the mat.\n",
            "Chinese: 猫睡在垫子上\n",
            "\n",
            "English: I love exploring new places.\n",
            "Chinese: 我喜欢探索新的地方\n",
            "\n",
            "English: This is a beautiful sunny day.\n",
            "Chinese: 这是一个美丽的阳光明媚的日子。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the translation pipeline\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-zh\", max_length=512, num_beams=4)\n",
        "\n",
        "# Function to translate text\n",
        "def translate_text(text):\n",
        "    # Use pipeline to translate\n",
        "    result = translator(text, max_length=512, num_beams=4, early_stopping=True)\n",
        "    translated_text = result[0][\"translation_text\"]\n",
        "    return translated_text\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample English texts\n",
        "    texts = [\n",
        "        \"The cat is sleeping on the mat.\",\n",
        "        \"I love exploring new places.\",\n",
        "        \"This is a beautiful sunny day.\"\n",
        "    ]\n",
        "    \n",
        "    # Translate each text\n",
        "    for text in texts:\n",
        "        translation = translate_text(text)\n",
        "        print(f\"English: {text}\")\n",
        "        print(f\"Chinese: {translation}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
